{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.exalumnos.usm.cl/wp-content/uploads/2015/06/Isotipo-Negro.gif\" title=\"Title text\" width=\"20%\" height=\"20%\" />\n",
    "\n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "<h1 align='center'> Binary Variational Semantic Hashing </h1>\n",
    "\n",
    "<H3 align='center'> Extensión trabajo CIARP </H3>\n",
    "<hr style=\"height:2px;border:none\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fmena/anaconda3/envs/tesis/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/fmena/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:469: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/fmena/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:470: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/fmena/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:471: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/fmena/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:472: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/fmena/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:473: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/fmena/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:476: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras,gc, os, time, sys\n",
    "from keras.layers import *\n",
    "from keras.models import Sequential,Model\n",
    "from keras import backend as K\n",
    "from astropy.table import Table\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from scipy.special import expit\n",
    "\n",
    "from base_networks import *\n",
    "from utils import check_availability, load_imgs_mask\n",
    "\n",
    "from utils import get_topK_labels,set_newlabel_list, enmask_data\n",
    "\n",
    "np.random.seed(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access Data/VGG_128: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!ls Data/VGG_128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "### MNIST\n",
    "---\n",
    "\n",
    "Imágenes en blanco y negro de 28x28 píxeles, de números del 0 al 9, que dan orígen a las 10 clases del problema.\n",
    "\n",
    "|Tipo set|Datos|Label|\n",
    "|---|---|---|\n",
    "|Entrenamiento|60000|10|\n",
    "|Pruebas|10000|10|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_dat = \"MNIST-raw\"\n",
    "\n",
    "(X_t, aux_t), (X_test, aux_test) = keras.datasets.mnist.load_data()\n",
    "labels = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "labels_t = np.asarray([labels[value] for value in aux_t])\n",
    "labels_test = np.asarray([labels[value] for value in aux_test])\n",
    "labels_t = np.concatenate((labels_t,labels_test),axis=0)\n",
    "\n",
    "X_t = np.concatenate([X_t, X_test], axis=0).reshape(len(labels_t),28*28)\n",
    "X_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 512)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_dat = \"MNIST\"\n",
    "\n",
    "(_, aux_t), (_, aux_test) = keras.datasets.mnist.load_data()\n",
    "labels = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "labels_t = np.asarray([labels[value] for value in aux_t])\n",
    "labels_test = np.asarray([labels[value] for value in aux_test])\n",
    "labels_t = np.concatenate((labels_t,labels_test),axis=0)\n",
    "\n",
    "X_t = np.load(\"../AUX/VGG_128/mnist_VGG_avg.npy\")\n",
    "\n",
    "X_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de datos Entrenamiento:  69000\n",
      "Cantidad de datos Pruebas:  1000\n"
     ]
    }
   ],
   "source": [
    "##### 1000 imagenes de prueba... \n",
    "from utils import sample_test_mask\n",
    "mask_train = sample_test_mask(labels_t, N=100, multi_label=False)\n",
    "\n",
    "## creat test como dicen...\n",
    "X_test = X_t[~mask_train]\n",
    "X_t = X_t[mask_train]\n",
    "labels_test = enmask_data(labels_t, ~mask_train)\n",
    "labels_t = enmask_data(labels_t, mask_train)\n",
    "\n",
    "gc.collect()\n",
    "print(\"Cantidad de datos Entrenamiento: \",len(X_t))\n",
    "print(\"Cantidad de datos Pruebas: \",len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### CIFAR-10\n",
    "---\n",
    "Imágenes RGB pequeñas de  32x32 píxeles, de fotos naturales de distintos objetos.\n",
    "\n",
    "|Tipo set|Datos|Label|\n",
    "|---|---|---|\n",
    "|Entrenamiento|50000|10|\n",
    "|Pruebas|10000|10|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 512)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_dat = \"CIFAR-10\"\n",
    "\n",
    "(_, aux_t), (_, aux_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "labels = [\"airplane\", \"automobile\",\"bird\", \"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]\n",
    "labels_t = np.asarray([labels[value[0]] for value in aux_t])\n",
    "labels_test = np.asarray([labels[value[0]] for value in aux_test])\n",
    "labels_t = np.concatenate((labels_t,labels_test),axis=0)\n",
    "\n",
    "\n",
    "X_t = np.load(\"../AUX/VGG_224/cifar10_VGG_avg.npy\") #mejora\n",
    "\n",
    "X_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de datos Entrenamiento:  59000\n",
      "Cantidad de datos Pruebas:  1000\n"
     ]
    }
   ],
   "source": [
    "##### 1000 imagenes de prueba... \n",
    "from utils import sample_test_mask\n",
    "mask_train = sample_test_mask(labels_t, N=100, multi_label=False)\n",
    "\n",
    "## creat test como dicen...\n",
    "X_test = X_t[~mask_train]\n",
    "X_t = X_t[mask_train]\n",
    "\n",
    "labels_test = enmask_data(labels_t, ~mask_train)\n",
    "labels_t = enmask_data(labels_t, mask_train)\n",
    "\n",
    "gc.collect()\n",
    "print(\"Cantidad de datos Entrenamiento: \",len(X_t))\n",
    "print(\"Cantidad de datos Pruebas: \",len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NUSWIDE\n",
    "---\n",
    "* Cantidad de datos totales: 269648\n",
    "* Datos utlizados (con imagenes disponibles a descargar): 169500\n",
    "* Datos top-21 clases: 158383\n",
    "\n",
    "Imágenes de eventos con 81 tópicos asociados, re-dimensionadas a 64x64.\n",
    "\n",
    "|Tipo set|Datos|Label|\n",
    "|---|---|---|\n",
    "|Entrenamiento|xxx|81|\n",
    "|Validación|xxx|81|\n",
    "|Pruebas|xxx|81|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de labels:  81\n",
      "Cantidad de objetos:  169500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['person'], ['person'], ['person'], ['person'], ['person']]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_dat = \"Nus-Wide\"\n",
    "\n",
    "\n",
    "mask_av = np.loadtxt(\"./Data/\"+name_dat+\"_mask_avail.txt\").astype(bool)\n",
    "\n",
    "folder = \"../Dataset_NUSWIDE/\"\n",
    "labels = pd.read_csv(folder+'Concepts81.txt',header=None).values.reshape(1,-1)[0]\n",
    "print(\"Cantidad de labels: \",len(labels) )\n",
    "\n",
    "labels_t = [[] for _ in range(269648)]\n",
    "for concept in labels:\n",
    "    aux = pd.read_csv(folder+\"Groundtruth/AllLabels/Labels_\"+concept+\".txt\",header=None)\n",
    "    indexs_true = aux.loc[(aux==1).values[:,0]].index\n",
    "    \n",
    "    for value in indexs_true:\n",
    "        labels_t[value].append(concept)\n",
    "        \n",
    "labels_t = enmask_data(labels_t, mask_av)\n",
    "N_total = len(labels_t)\n",
    "print(\"Cantidad de objetos: \",N_total )\n",
    "\n",
    "labels_t[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get top-K labels data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category with most data (sky) has = 61066, the top-K category (mountain) has = 4232\n",
      "Cantidad de objetos:  158383\n"
     ]
    }
   ],
   "source": [
    "new_labels = get_topK_labels(labels_t, labels, K=21)\n",
    "\n",
    "labels_t = set_newlabel_list(new_labels, labels_t)\n",
    "labels = new_labels\n",
    "# y si quedan datos sin clase?\n",
    "mask_used_t = np.asarray(list(map(len,labels_t))) != 0\n",
    "\n",
    "labels_t = enmask_data(labels_t, mask_used_t)\n",
    "print(\"Cantidad de objetos: \", len(labels_t) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N_used = 80*1000 #o 150k??\n",
    "idx_all = np.arange(0, N_total)\n",
    "mask_used = np.zeros(N_total, dtype=bool)\n",
    "mask_used[np.random.choice(np.arange(0, N_total), size=N_used, replace=False)] = 1\n",
    "mask_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158383, 512)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t = np.load(\"../AUX/VGG_224/nuswide_VGG_avg.npy\")\n",
    "\n",
    "X_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de datos Entrenamiento:  156283\n",
      "Cantidad de datos Pruebas:  2100\n"
     ]
    }
   ],
   "source": [
    "from utils import sample_test_mask\n",
    "mask_train = sample_test_mask(labels_t, N=100)\n",
    "\n",
    "## creat test como dicen...\n",
    "X_test = X_t[~mask_train]\n",
    "X_t = X_t[mask_train]\n",
    "labels_test = enmask_data(labels_t, ~mask_train)\n",
    "labels_t = enmask_data(labels_t, mask_train)\n",
    "\n",
    "gc.collect()\n",
    "print(\"Cantidad de datos Entrenamiento: \",len(X_t))\n",
    "print(\"Cantidad de datos Pruebas: \",len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### CelebA\n",
    "---\n",
    "* Cantidad de datos totales: 202599\n",
    "* Datos en plataforma Kaggle:https://www.kaggle.com/jessicali9530/celeba-dataset \n",
    "\n",
    "Imágenes RGB re-dimensionadas a 64x64 píxeles, de fotos naturales de rostros de celebridades. Una muestra es utilizada\n",
    "\n",
    "|Tipo set|Datos|Label|\n",
    "|---|---|---|\n",
    "|Entrenamiento|xxx|40|\n",
    "|Validación|xxx|40|\n",
    "|Pruebas|xxx|40|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mask_av = check_availability(folder+\"small_images/\", labels_t)\n",
    "np.savetxt(\"./Data/+\"name_dat+\"_mask_avail.txt\", mask_av, fmt=\"%1i\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de labels:  40\n",
      "Cantidad de objetos:  202599\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['5_o_Clock_Shadow',\n",
       " 'Arched_Eyebrows',\n",
       " 'Attractive',\n",
       " 'Bags_Under_Eyes',\n",
       " 'Bald']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_dat = \"CelebA\"\n",
    "mask_av = np.loadtxt(\"./Data/\"+name_dat+\"_mask_avail.txt\").astype(bool)\n",
    "\n",
    "folder = \"../CelebA/\"\n",
    "\n",
    "part = pd.read_csv(folder+\"list_eval_partition.csv\")\n",
    "mask_train = (part[\"partition\"].values == 0)[mask_av]\n",
    "mask_val = (part[\"partition\"].values == 1)[mask_av]\n",
    "mask_test = (part[\"partition\"].values == 2)[mask_av]\n",
    "\n",
    "df_atrr = pd.read_csv(folder+\"list_attr_celeba.csv\")[mask_av]\n",
    "img_names = df_atrr[\"image_id\"].values\n",
    "labels = list(df_atrr.columns[1:])\n",
    "print(\"Cantidad de labels: \",len(labels) )\n",
    "\n",
    "N_total = len(df_atrr)\n",
    "print(\"Cantidad de objetos: \",N_total )\n",
    "aux = (df_atrr == 1).values\n",
    "labels_t = np.asarray([list(df_atrr.columns[aux[value]]) for value in range(N_total)])\n",
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(202599, 512)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t = np.load(\"./Data/VGG_128/celeba_VGG_avg.npy\")\n",
    "X_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de datos Entrenamiento:  198599\n",
      "Cantidad de datos Pruebas:  4000\n"
     ]
    }
   ],
   "source": [
    "from utils import sample_test_mask\n",
    "mask_train = sample_test_mask(labels_t, N=100)\n",
    "\n",
    "## creat test como dicen...\n",
    "X_test = X_t[~mask_train]\n",
    "X_t = X_t[mask_train]\n",
    "labels_test = enmask_data(labels_t, ~mask_train)\n",
    "labels_t = enmask_data(labels_t, mask_train)\n",
    "\n",
    "gc.collect()\n",
    "print(\"Cantidad de datos Entrenamiento: \",len(X_t))\n",
    "print(\"Cantidad de datos Pruebas: \",len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation creation\n",
    "\n",
    "Pre-process: División por 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t = X_t.astype(\"float32\")/255\n",
    "X_test = X_test.astype(\"float32\")/255\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.23897482, -0.07967994, -0.5255795 , ...,  2.0275059 ,\n",
       "        -0.7924833 , -0.2824458 ],\n",
       "       [-0.46935815, -0.42472827, -0.5255795 , ..., -0.3618986 ,\n",
       "        -0.77227414,  0.65443707],\n",
       "       [-0.46935815,  0.70256346, -0.08978007, ...,  1.8037844 ,\n",
       "        -0.8723501 , -0.39973858],\n",
       "       ...,\n",
       "       [-0.19930203, -0.06644024, -0.4754263 , ..., -0.1621323 ,\n",
       "        -0.84103304, -0.37144858],\n",
       "       [ 0.60610616, -0.4239209 ,  1.9280208 , ...,  0.3177703 ,\n",
       "        -0.44614175, -0.3986869 ],\n",
       "       [ 6.8804135 , -0.08250271, -0.2630449 , ..., -0.43003082,\n",
       "        -0.24525562, -0.03919934]], dtype=float32)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "std = StandardScaler(with_mean=True, with_std=True)\n",
    "std.fit(X_t)\n",
    "\n",
    "X_t = std.transform(X_t)\n",
    "X_test = std.transform(X_test)\n",
    "X_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de datos Entrenamiento:  154183\n",
      "Cantidad de datos Validación:  2100\n",
      "Cantidad de datos Pruebas:  2100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, labels_train, labels_val  = train_test_split(X_t, labels_t, random_state=20,test_size=len(X_test))\n",
    "\n",
    "print(\"Cantidad de datos Entrenamiento: \",len(X_train))\n",
    "print(\"Cantidad de datos Validación: \",len(X_val))\n",
    "print(\"Cantidad de datos Pruebas: \",len(X_test))\n",
    "del X_t, labels_t\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_input = X_train\n",
    "X_val_input = X_val\n",
    "X_test_input = X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture\n",
    "---\n",
    "CNN\n",
    "https://github.com/rtflynn/Cifar-Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def REC_loss(x_true, x_pred):\n",
    "    if raw:\n",
    "        return K.mean( K.binary_crossentropy(x_true, x_pred), axis=-1)\n",
    "    else:\n",
    "        return K.mean( (x_true- x_pred)**2 ,axis=-1)  #it should be VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "def sample_gumbel(shape,eps=K.epsilon()):\n",
    "    \"\"\"Inverse Sample function from Gumbel(0, 1)\"\"\"\n",
    "    U = K.random_uniform(shape, 0, 1)\n",
    "    return K.log(U + eps)- K.log(1-U + eps)\n",
    "\n",
    "def binary_VAE(data_dim,Nb,units,layers_e,layers_d,opt='adam',BN=True,beta=0., lamb=0., summ=True):\n",
    "    tau = K.variable(0.67, name=\"temperature\") #o tau fijo en 0.67=2/3\n",
    "    \n",
    "    pre_encoder = define_pre_encoder(data_dim, layers=layers_e,units=units,BN=BN)\n",
    "    if raw:\n",
    "        generator = define_generator(Nb,data_dim,layers=layers_d,units=units,BN=BN, out_type='sigmoid')\n",
    "    else:\n",
    "        generator = define_generator(Nb,data_dim,layers=layers_d,units=units,BN=BN, out_type='linear')\n",
    "    if summ:\n",
    "        print(\"pre-encoder network:\")\n",
    "        pre_encoder.summary()\n",
    "        print(\"generator network:\")\n",
    "        generator.summary()\n",
    "\n",
    "    x = Input(shape=(data_dim,))\n",
    "    hidden = pre_encoder(x)\n",
    "    logits_b  = Dense(Nb, activation='linear', name='logits-b')(hidden) #log(B_j/1-B_j)\n",
    "    #proba = np.exp(logits_b)/(1+np.exp(logits_b)) = sigmoidal(logits_b) <<<<<<<<<< recupera probabilidad\n",
    "    #dist = Dense(Nb, activation='sigmoid')(hidden) #p(b) #otra forma de modelarlo\n",
    "    encoder = Model(x, logits_b)\n",
    "\n",
    "    def sampling(logits_b):\n",
    "        #logits_b = K.log(aux/(1-aux) + K.epsilon() )\n",
    "        b = logits_b + sample_gumbel(K.shape(logits_b)) # logits + gumbel noise\n",
    "        return keras.activations.sigmoid( b/tau )\n",
    "\n",
    "    b_sampled = Lambda(sampling, output_shape=(Nb,), name='sampled')(logits_b)\n",
    "    output = generator(b_sampled)\n",
    "        \n",
    "    Recon_loss = REC_loss\n",
    "    kl_loss = BKL_loss(logits_b)\n",
    "    info_kl_loss = info_BKL_loss(logits_b) #over minibatch\n",
    "    def BVAE_loss(y_true, y_pred): \n",
    "        return Recon_loss(y_true, y_pred) + beta*kl_loss(y_true, y_pred) + lamb*info_kl_loss(y_true,y_pred)\n",
    "\n",
    "    binary_vae = Model(x, output)\n",
    "    binary_vae.compile(optimizer=opt, loss=BVAE_loss, metrics = [Recon_loss,kl_loss,info_kl_loss])\n",
    "    return binary_vae, encoder,generator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train details\n",
    "---\n",
    "\n",
    "* 30* epochs* \n",
    "* *batch size* de 200\n",
    "* optimizador Adam\n",
    "* Inicializador de Glorot (para los pesos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import  compare_hist_train, add_hist_plot\n",
    "\n",
    "batch_size = 100*2 #ya que son datasets mas grandes\n",
    "epochs = 30 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/casapanshop/anaconda2/envs/newpy3_tf1/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/casapanshop/anaconda2/envs/newpy3_tf1/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/casapanshop/anaconda2/envs/newpy3_tf1/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/casapanshop/anaconda2/envs/newpy3_tf1/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/casapanshop/anaconda2/envs/newpy3_tf1/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1702: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/casapanshop/anaconda2/envs/newpy3_tf1/lib/python3.6/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/casapanshop/anaconda2/envs/newpy3_tf1/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "***************************************\n",
      "*********** SUMMARY RESULTS ***********\n",
      "***************************************\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lambda</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.8323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>0.8339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>0.8287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>0.8317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>0.8295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.8371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>0.8315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.8198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>0.7975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>0.7293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>0.6239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>0.5592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.000000e+05</td>\n",
       "      <td>0.5943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>0.5880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          lambda   score\n",
       "0   1.000000e-07  0.8323\n",
       "1   1.000000e-06  0.8339\n",
       "2   1.000000e-05  0.8287\n",
       "3   1.000000e-04  0.8317\n",
       "4   1.000000e-03  0.8295\n",
       "5   1.000000e-02  0.8371\n",
       "6   1.000000e-01  0.8315\n",
       "7   1.000000e+00  0.8198\n",
       "8   1.000000e+01  0.7975\n",
       "9   1.000000e+02  0.7293\n",
       "10  1.000000e+03  0.6239\n",
       "11  1.000000e+04  0.5592\n",
       "12  1.000000e+05  0.5943\n",
       "13  1.000000e+06  0.5880"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value is 0.8371 with lambda 0.010000\n",
      "Worst value is 0.5593 with lambda 10000.000000\n",
      "***************************************\n"
     ]
    }
   ],
   "source": [
    "#from utils import find_lambda\n",
    "\n",
    "def create_model_B(lambda_V):\n",
    "    return binary_VAE(X_train_input.shape[1],Nb=32,units=500,layers_e=2,layers_d=0\n",
    "                                                                  ,beta=0, lamb=lambda_V, summ=False)\n",
    "\n",
    "lambda_B = find_lambda(create_model_B, X_train_input, X_train, X_val_input,labels_train,labels_val,\n",
    "                   binary=True, BS=batch_size)\n",
    "#mnist -- raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_V_found = {\"mnist-raw\":1e-2, \"mnist\":1e-2, \"cifar-10\":1e1, \"nus-wide\":1e1} #values for sum\n",
    "\n",
    "lambda_B = lambda_V_found[name_dat.lower()]\n",
    "lambda_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-encoder network:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               256500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 500)               2000      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 500)               2000      \n",
      "=================================================================\n",
      "Total params: 511,000\n",
      "Trainable params: 509,000\n",
      "Non-trainable params: 2,000\n",
      "_________________________________________________________________\n",
      "generator network:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               16896     \n",
      "=================================================================\n",
      "Total params: 16,896\n",
      "Trainable params: 16,896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 154183 samples, validate on 2100 samples\n",
      "Epoch 1/30\n",
      "154183/154183 [==============================] - 2s - loss: 0.8850 - REC_loss: 0.8457 - KL: 0.2749 - infoKL: 0.0039 - val_loss: 1.2397 - val_REC_loss: 0.7919 - val_KL: 0.3147 - val_infoKL: 0.0448\n",
      "Epoch 2/30\n",
      "154183/154183 [==============================] - 2s - loss: 0.8165 - REC_loss: 0.7765 - KL: 0.3078 - infoKL: 0.0040 - val_loss: 1.2437 - val_REC_loss: 0.7711 - val_KL: 0.3254 - val_infoKL: 0.0473\n",
      "Epoch 3/30\n",
      "154183/154183 [==============================] - 2s - loss: 0.8050 - REC_loss: 0.7642 - KL: 0.3160 - infoKL: 0.0041 - val_loss: 1.2019 - val_REC_loss: 0.7643 - val_KL: 0.3308 - val_infoKL: 0.0438\n",
      "Epoch 4/30\n",
      "154183/154183 [==============================] - 2s - loss: 0.7992 - REC_loss: 0.7586 - KL: 0.3196 - infoKL: 0.0041 - val_loss: 1.1891 - val_REC_loss: 0.7596 - val_KL: 0.3270 - val_infoKL: 0.0429\n",
      "Epoch 5/30\n",
      "154183/154183 [==============================] - 2s - loss: 0.7949 - REC_loss: 0.7546 - KL: 0.3231 - infoKL: 0.0040 - val_loss: 1.2202 - val_REC_loss: 0.7556 - val_KL: 0.3307 - val_infoKL: 0.0465\n",
      "Epoch 6/30\n",
      "154183/154183 [==============================] - 2s - loss: 0.7928 - REC_loss: 0.7517 - KL: 0.3261 - infoKL: 0.0041 - val_loss: 1.2297 - val_REC_loss: 0.7516 - val_KL: 0.3368 - val_infoKL: 0.0478\n",
      "Epoch 7/30\n",
      "154183/154183 [==============================] - 2s - loss: 0.7906 - REC_loss: 0.7496 - KL: 0.3277 - infoKL: 0.0041 - val_loss: 1.2259 - val_REC_loss: 0.7522 - val_KL: 0.3347 - val_infoKL: 0.0474\n",
      "Epoch 8/30\n",
      "154183/154183 [==============================] - 2s - loss: 0.7875 - REC_loss: 0.7470 - KL: 0.3311 - infoKL: 0.0041 - val_loss: 1.1862 - val_REC_loss: 0.7496 - val_KL: 0.3347 - val_infoKL: 0.0437\n",
      "Epoch 9/30\n",
      "154183/154183 [==============================] - 2s - loss: 0.7871 - REC_loss: 0.7463 - KL: 0.3298 - infoKL: 0.0041 - val_loss: 1.2052 - val_REC_loss: 0.7486 - val_KL: 0.3368 - val_infoKL: 0.0457\n",
      "Epoch 10/30\n",
      "154183/154183 [==============================] - 2s - loss: 0.7861 - REC_loss: 0.7452 - KL: 0.3299 - infoKL: 0.0041 - val_loss: 1.2183 - val_REC_loss: 0.7474 - val_KL: 0.3368 - val_infoKL: 0.0471\n",
      "Epoch 11/30\n",
      "154183/154183 [==============================] - 2s - loss: 0.7838 - REC_loss: 0.7436 - KL: 0.3324 - infoKL: 0.0040 - val_loss: 1.2152 - val_REC_loss: 0.7447 - val_KL: 0.3395 - val_infoKL: 0.0470\n",
      "Epoch 12/30\n",
      "154183/154183 [==============================] - 2s - loss: 0.7823 - REC_loss: 0.7421 - KL: 0.3350 - infoKL: 0.0040 - val_loss: 1.2120 - val_REC_loss: 0.7439 - val_KL: 0.3404 - val_infoKL: 0.0468\n",
      "Epoch 13/30\n",
      "154183/154183 [==============================] - 2s - loss: 0.7813 - REC_loss: 0.7412 - KL: 0.3353 - infoKL: 0.0040 - val_loss: 1.1952 - val_REC_loss: 0.7426 - val_KL: 0.3419 - val_infoKL: 0.0453\n",
      "Epoch 14/30\n",
      "154183/154183 [==============================] - 2s - loss: 0.7791 - REC_loss: 0.7398 - KL: 0.3367 - infoKL: 0.0039 - val_loss: 1.2448 - val_REC_loss: 0.7425 - val_KL: 0.3417 - val_infoKL: 0.0502\n",
      "Epoch 15/30\n",
      "154183/154183 [==============================] - 2s - loss: 0.7785 - REC_loss: 0.7391 - KL: 0.3366 - infoKL: 0.0039 - val_loss: 1.2002 - val_REC_loss: 0.7423 - val_KL: 0.3402 - val_infoKL: 0.0458\n",
      "Epoch 16/30\n",
      "154183/154183 [==============================] - 2s - loss: 0.7767 - REC_loss: 0.7380 - KL: 0.3398 - infoKL: 0.0039 - val_loss: 1.2110 - val_REC_loss: 0.7405 - val_KL: 0.3437 - val_infoKL: 0.0470\n",
      "Epoch 17/30\n",
      "154183/154183 [==============================] - 2s - loss: 0.7758 - REC_loss: 0.7370 - KL: 0.3407 - infoKL: 0.0039 - val_loss: 1.1880 - val_REC_loss: 0.7395 - val_KL: 0.3461 - val_infoKL: 0.0448\n",
      "Epoch 18/30\n",
      "154183/154183 [==============================] - 2s - loss: 0.7749 - REC_loss: 0.7363 - KL: 0.3415 - infoKL: 0.0039 - val_loss: 1.2067 - val_REC_loss: 0.7401 - val_KL: 0.3444 - val_infoKL: 0.0467\n",
      "Epoch 19/30\n",
      "154183/154183 [==============================] - 2s - loss: 0.7733 - REC_loss: 0.7355 - KL: 0.3430 - infoKL: 0.0038 - val_loss: 1.2006 - val_REC_loss: 0.7385 - val_KL: 0.3465 - val_infoKL: 0.0462\n",
      "Epoch 20/30\n",
      "154183/154183 [==============================] - 2s - loss: 0.7719 - REC_loss: 0.7345 - KL: 0.3445 - infoKL: 0.0037 - val_loss: 1.2191 - val_REC_loss: 0.7372 - val_KL: 0.3502 - val_infoKL: 0.0482\n",
      "Epoch 21/30\n",
      "154183/154183 [==============================] - 2s - loss: 0.7707 - REC_loss: 0.7334 - KL: 0.3457 - infoKL: 0.0037 - val_loss: 1.2098 - val_REC_loss: 0.7372 - val_KL: 0.3490 - val_infoKL: 0.0473\n",
      "Epoch 22/30\n",
      "154183/154183 [==============================] - 2s - loss: 0.7690 - REC_loss: 0.7327 - KL: 0.3466 - infoKL: 0.0036 - val_loss: 1.2162 - val_REC_loss: 0.7360 - val_KL: 0.3499 - val_infoKL: 0.0480\n",
      "Epoch 23/30\n",
      "154183/154183 [==============================] - 2s - loss: 0.7688 - REC_loss: 0.7321 - KL: 0.3482 - infoKL: 0.0037 - val_loss: 1.1877 - val_REC_loss: 0.7353 - val_KL: 0.3491 - val_infoKL: 0.0452\n",
      "Epoch 24/30\n",
      "154183/154183 [==============================] - 2s - loss: 0.7669 - REC_loss: 0.7314 - KL: 0.3497 - infoKL: 0.0035 - val_loss: 1.1847 - val_REC_loss: 0.7331 - val_KL: 0.3544 - val_infoKL: 0.0452\n",
      "Epoch 25/30\n",
      "154183/154183 [==============================] - 2s - loss: 0.7652 - REC_loss: 0.7302 - KL: 0.3528 - infoKL: 0.0035 - val_loss: 1.2044 - val_REC_loss: 0.7325 - val_KL: 0.3565 - val_infoKL: 0.0472\n",
      "Epoch 26/30\n",
      "154183/154183 [==============================] - 2s - loss: 0.7641 - REC_loss: 0.7295 - KL: 0.3521 - infoKL: 0.0035 - val_loss: 1.2089 - val_REC_loss: 0.7329 - val_KL: 0.3557 - val_infoKL: 0.0476\n",
      "Epoch 27/30\n",
      "154183/154183 [==============================] - 2s - loss: 0.7630 - REC_loss: 0.7289 - KL: 0.3531 - infoKL: 0.0034 - val_loss: 1.1987 - val_REC_loss: 0.7327 - val_KL: 0.3562 - val_infoKL: 0.0466\n",
      "Epoch 28/30\n",
      "154183/154183 [==============================] - 2s - loss: 0.7617 - REC_loss: 0.7283 - KL: 0.3547 - infoKL: 0.0033 - val_loss: 1.2058 - val_REC_loss: 0.7316 - val_KL: 0.3577 - val_infoKL: 0.0474\n",
      "Epoch 29/30\n",
      "154183/154183 [==============================] - 2s - loss: 0.7601 - REC_loss: 0.7274 - KL: 0.3559 - infoKL: 0.0033 - val_loss: 1.1808 - val_REC_loss: 0.7318 - val_KL: 0.3598 - val_infoKL: 0.0449\n",
      "Epoch 30/30\n",
      "154183/154183 [==============================] - 2s - loss: 0.7588 - REC_loss: 0.7266 - KL: 0.3574 - infoKL: 0.0032 - val_loss: 1.2125 - val_REC_loss: 0.7312 - val_KL: 0.3596 - val_infoKL: 0.0481\n"
     ]
    }
   ],
   "source": [
    "binary_vae,encoder_Bvae,generator_Bvae= binary_VAE(X_train.shape[1],Nb=32,units=500,layers_e=2,layers_d=0,beta=0,lamb=lambda_B)\n",
    "\n",
    "hist2 = binary_vae.fit(X_train_input, X_train, epochs=epochs, batch_size=batch_size\n",
    "                           ,validation_data=(X_val_input,X_val) )\n",
    "                       #,callbacks=[Tau_Call(tau)] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another intrinsic measure: *Classification*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#function to define and train model\n",
    "from sklearn.metrics import jaccard_score\n",
    "from utils import define_fit, MedianHashing, visualize_probas, visualize_mean, calculate_hash,visualize_probas_byB\n",
    "\n",
    "results = []\n",
    "results_S = []\n",
    "results_B = []\n",
    "results_O_B = [] #original testing on tresholded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoder_Bvae' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-31f7b658f3cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#codify input data (binarize -- or aprox)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_Bvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX_val_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_Bvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'encoder_Bvae' is not defined"
     ]
    }
   ],
   "source": [
    "#codify input data (binarize -- or aprox)\n",
    "X_train_logits = encoder_Bvae.predict(X_train_input)\n",
    "X_val_logits = encoder_Bvae.predict(X_test_input)\n",
    "\n",
    "#probabilities\n",
    "X_train_Bcode = expit(X_train_logits)\n",
    "X_val_Bcode = expit(X_val_logits)\n",
    "\n",
    "##codify labels\n",
    "labels_aux = np.asarray(labels)\n",
    "def codify_labels(inputs):\n",
    "    inputs = np.asarray(inputs)\n",
    "    matrix_labels = np.zeros((inputs.shape[0],labels_aux.shape[0]))\n",
    "    for i,aux_labels in enumerate(inputs):\n",
    "        if type(aux_labels) == list or type(aux_labels) == np.ndarray :\n",
    "            for aux_label in aux_labels:\n",
    "                idx = np.where(aux_label==labels_aux)[0]\n",
    "                matrix_labels[i,idx] = 1 #various-multiple\n",
    "        else:\n",
    "            idx = np.where(aux_labels==labels_aux)[0]\n",
    "            matrix_labels[i,idx] = 1 #only one\n",
    "    return matrix_labels\n",
    "\n",
    "C_train = codify_labels(labels_train)\n",
    "#C_val = codify_labels(labels_val)\n",
    "C_val = codify_labels(labels_test)\n",
    "C_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'name_dat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-91ee497e802f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_dat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvisualize_probas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_Bcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvisualize_probas_byB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_Bcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'name_dat' is not defined"
     ]
    }
   ],
   "source": [
    "print(name_dat)\n",
    "visualize_probas(X_train_logits, X_train_Bcode)\n",
    "\n",
    "visualize_probas_byB(X_train_Bcode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'name_dat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-91ee497e802f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_dat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvisualize_probas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_Bcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvisualize_probas_byB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_Bcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'name_dat' is not defined"
     ]
    }
   ],
   "source": [
    "print(name_dat)\n",
    "visualize_probas(X_train_logits, X_train_Bcode)\n",
    "\n",
    "visualize_probas_byB(X_train_Bcode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'name_dat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-91ee497e802f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_dat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvisualize_probas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_Bcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvisualize_probas_byB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_Bcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'name_dat' is not defined"
     ]
    }
   ],
   "source": [
    "print(name_dat)\n",
    "visualize_probas(X_train_logits, X_train_Bcode)\n",
    "\n",
    "visualize_probas_byB(X_train_Bcode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'name_dat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-91ee497e802f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_dat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvisualize_probas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_Bcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvisualize_probas_byB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_Bcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'name_dat' is not defined"
     ]
    }
   ],
   "source": [
    "print(name_dat)\n",
    "visualize_probas(X_train_logits, X_train_Bcode)\n",
    "\n",
    "visualize_probas_byB(X_train_Bcode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'name_dat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1d8497b74e0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mname_dat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmulti_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"celeba\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maux\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"nus-wide\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maux\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel1_O\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefine_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulti_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train_Bcode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mC_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'name_dat' is not defined"
     ]
    }
   ],
   "source": [
    "aux = [name_dat.lower()]\n",
    "multi_label = \"celeba\" in aux or \"nus-wide\" in aux\n",
    "\n",
    "model1_O = define_fit(multi_label,X_train_Bcode,C_train)\n",
    "\n",
    "if not multi_label:\n",
    "    aux.append(model1_O.evaluate(X_train_Bcode,C_train,verbose=0)[1])\n",
    "    aux.append(model1_O.evaluate(X_val_Bcode,C_val,verbose=0)[1])\n",
    "else:\n",
    "    aux.append(jaccard_score(C_train, (model1_O.predict(X_train_Bcode)>=0.5)*1, average='micro'))\n",
    "    aux.append(jaccard_score(C_val, (model1_O.predict(X_val_Bcode)>=0.5)*1, average='micro'))\n",
    "    \n",
    "results.append(aux)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d91f9628943e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mvalores\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nAccuracy on dataset: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Binary VAE (train-val): %f - %f\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "for valores in results:\n",
    "    print(\"\\nAccuracy on dataset: \",valores[0])\n",
    "    print(\"Binary VAE (train-val): %f - %f\"%(valores[1],valores[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'calculate_hash' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-96051fbfa730>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## binary // treshold it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train_Bcode_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_Bcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_probas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX_val_Bcode_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_Bcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_probas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_train_Bcode_B\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'calculate_hash' is not defined"
     ]
    }
   ],
   "source": [
    "## binary // treshold it\n",
    "X_train_Bcode_B = calculate_hash(X_train_Bcode, from_probas=True, from_logits=False)\n",
    "X_val_Bcode_B = calculate_hash(X_val_Bcode, from_probas=True, from_logits=False)\n",
    "\n",
    "X_train_Bcode_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'name_dat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-fc8b107798cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### trained models over encoder representation testing on tresholded representation (see how decrease)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mname_dat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmulti_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"celeba\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maux\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"nus-wide\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maux\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmulti_label\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'name_dat' is not defined"
     ]
    }
   ],
   "source": [
    "### trained models over encoder representation testing on tresholded representation (see how decrease)\n",
    "aux = [name_dat.lower()]\n",
    "multi_label = \"celeba\" in aux or \"nus-wide\" in aux\n",
    "\n",
    "if not multi_label:\n",
    "    aux.append(model1_O.evaluate(X_train_Bcode_B,C_train,verbose=0)[1])\n",
    "    aux.append(model1_O.evaluate(X_val_Bcode_B,C_val,verbose=0)[1])\n",
    "else:\n",
    "    aux.append(jaccard_score(C_train, (model1_O.predict(X_train_Bcode_B)>=0.5)*1, average='micro'))\n",
    "    aux.append(jaccard_score(C_val, (model1_O.predict(X_val_Bcode_B)>=0.5)*1, average='micro'))\n",
    "    \n",
    "results_O_B.append(aux)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification on Binary (thresholded) representation\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'results_O_B' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-451964ec14d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Classification on Binary (thresholded) representation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mvalores\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults_O_B\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nAccuracy on dataset: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Binary VAE (train-val): %f - %f\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results_O_B' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Classification on Binary (thresholded) representation\")\n",
    "for valores in results_O_B:\n",
    "    print(\"\\nAccuracy on dataset: \",valores[0])\n",
    "    print(\"Binary VAE (train-val): %f - %f\"%(valores[1],valores[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'name_dat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-53135ebde38c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mname_dat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmulti_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"celeba\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maux\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"nus-wide\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maux\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefine_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulti_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train_Bcode_B\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mC_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'name_dat' is not defined"
     ]
    }
   ],
   "source": [
    "aux = [name_dat.lower()]\n",
    "multi_label = \"celeba\" in aux or \"nus-wide\" in aux\n",
    "\n",
    "model1 = define_fit(multi_label,X_train_Bcode_B,C_train)\n",
    "\n",
    "if not multi_label:\n",
    "    aux.append(model1.evaluate(X_train_Bcode_B,C_train,verbose=0)[1])\n",
    "    aux.append(model1.evaluate(X_val_Bcode_B,C_val,verbose=0)[1])\n",
    "else:\n",
    "    aux.append(jaccard_score(C_train, (model1.predict(X_train_Bcode_B)>=0.5)*1, average='micro'))\n",
    "    aux.append(jaccard_score(C_val, (model1.predict(X_val_Bcode_B)>=0.5)*1, average='micro'))\n",
    "    \n",
    "results_B.append(aux)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification on Binary representation\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'results_B' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-7997da6ad591>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Classification on Binary representation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mvalores\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults_B\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nAccuracy on dataset: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Binary VAE (train-val): %f - %f\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results_B' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Classification on Binary representation\")\n",
    "for valores in results_B:\n",
    "    print(\"\\nAccuracy on dataset: \",valores[0])\n",
    "    print(\"Binary VAE (train-val): %f - %f\"%(valores[1],valores[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Results\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils import MedianHashing, get_similar, measure_metrics, calculate_hash\n",
    "from utils import MAP_atk, M_P_atk, AP_atk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimentación\n",
    "---\n",
    "A continación se realizan las experimentaciones correspondientes para encontrar la mejor arquitectura y mejor configuración del modelo propuesto en base a las métricas *precision* y *recall* del conjunto de validación en el **top 100** de elementos recuperados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_hashingB(encoder,train,val,labels_train,labels_val,traditional=True,tipo=\"topK\",K=100):\n",
    "    encode_train = encoder.predict(train)\n",
    "    encode_val = encoder.predict(val)\n",
    "    \n",
    "    train_hash = calculate_hash(encode_train, from_probas=~traditional )\n",
    "    val_hash = calculate_hash(encode_val, from_probas=~traditional)\n",
    "\n",
    "    val_similares_train =  get_similar(val_hash, train_hash, tipo=tipo,K=K) \n",
    "\n",
    "    return measure_metrics(labels,val_similares_train,labels_query=labels_val,labels_source=labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Experimentando variando el #Bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binary_dat = {\"mnist\":{\"p\":[],\"r\":[]},\"cifar-10\":{\"p\":[],\"r\":[]},\n",
    "              \"celeba\":{\"p\":[],\"r\":[]},'nus-wide':{\"p\":[],\"r\":[]},\n",
    "               \"mnist-raw\":{\"p\":[],\"r\":[]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-f1d7a2c2d998>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mNbits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname_dat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mNbit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mNbits\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbinary_vae\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder_Bvae\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgenerator_Bvae\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mbinary_VAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNbit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayers_e\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayers_d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlamb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlambda_B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "Nbits = np.asarray([4,8,16,32,64])\n",
    "dataset = name_dat.lower()\n",
    "\n",
    "for Nbit in Nbits:    \n",
    "    binary_vae,encoder_Bvae,generator_Bvae= binary_VAE(X_train.shape[1],Nb=Nbit,units=500,layers_e=2,layers_d=0,beta=0,lamb=lambda_B)\n",
    "    hist2 = binary_vae.fit(X_train_input, X_train, epochs=epochs, batch_size=batch_size, verbose=0\n",
    "                           ,validation_data=(X_val_input,X_val) )\n",
    "    p_b,r_b = evaluate_hashingB(encoder_Bvae,X_train_input,X_val_input,labels_train,labels_val,traditional=False,tipo=\"topK\")\n",
    "    binary_dat[dataset][\"p\"].append(p_b) \n",
    "    binary_dat[dataset][\"r\"].append(r_b) \n",
    "    del binary_vae, encoder_Bvae, generator_Bvae\n",
    "    keras.backend.clear_session()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de Precision en validación\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-a220cb1905d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Resultados de Precision en validación\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Table()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"N bits\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNbits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"MNIST-R\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinary_dat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mnist-raw\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"p\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"MNIST\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinary_dat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mnist\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"p\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Resultados de Precision en validación\")\n",
    "t = pd.DataFrame() #Table()\n",
    "t[\"N bits\"] = Nbits\n",
    "t[\"MNIST-R\"] = binary_dat[\"mnist-raw\"][\"p\"]\n",
    "t[\"MNIST\"] = binary_dat[\"mnist\"][\"p\"]\n",
    "t[\"CIFAR-10\"] = binary_dat[\"cifar-10\"][\"p\"]\n",
    "t[\"Nus-Wide\"] = binary_dat[\"nus-wide\"][\"p\"]\n",
    "print(\"\\n*** VAE Binary***\")\n",
    "print(t.T)\n",
    "\n",
    "print(\"\\nResultados de Recall en validación\")\n",
    "t = pd.DataFrame() #Table()\n",
    "t[\"N bits\"] = Nbits\n",
    "t[\"MNIST-R\"] = binary_dat[\"mnist-raw\"][\"r\"]\n",
    "t[\"MNIST\"] = binary_dat[\"mnist\"][\"r\"]\n",
    "t[\"CIFAR-10\"] = binary_dat[\"cifar-10\"][\"r\"]\n",
    "t[\"Nus-Wide\"] = binary_dat[\"nus-wide\"][\"r\"]\n",
    "print(\"\\n*** VAE Binary***\")\n",
    "print(t.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Best models facing test set*\n",
    "Luego de la selección de la mejor configuración de los modelos se evalua de diferentes formas sobre el conjunto de pruebas de los distintos *datasets*, los cambios realizados son:\n",
    "* Se entrenan sobre todos los datos disponibles (*train+val*)\n",
    "* Se aumentó el número de *epochs* a 50.\n",
    "\n",
    "El mejor modelo:\n",
    "* Simétrica para *Binary VAE* y Base para *Traditional VAE*\n",
    "* 32 Bits en la codificación (número de variables latentes)\n",
    "* Representación sobre las top 10 mil *tokens* más frecuentes y *Term Frequency*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import calculate_hash\n",
    "def evaluate_hashing_DE(train_hash,test_hash,labels_trainn,labels_testt,tipo=\"topK\",eval_tipo='PRatk',K=100):\n",
    "    \"\"\"\n",
    "        Evaluate Hashing correclty: Query and retrieve on a different set\n",
    "    \"\"\"\n",
    "    test_similares_train =  get_similar(test_hash,train_hash,tipo=tipo,K=K)\n",
    "    if eval_tipo==\"MAP\":\n",
    "        return MAP_atk(test_similares_train,labels_query=labels_testt, labels_source=labels_trainn, K=0) #all ranking\n",
    "    elif eval_tipo == \"PRatk\":\n",
    "        return measure_metrics(labels,test_similares_train,labels_testt,labels_source=labels_trainn)\n",
    "    elif eval_tipo == \"Patk\":\n",
    "        return M_P_atk(test_similares_train, labels_query=labels_testt, labels_source=labels_trainn, K=K)\n",
    "\n",
    "def hash_data(model, x_train, x_test, binary=True):\n",
    "    encode_train = model.predict(x_train)\n",
    "    encode_test = model.predict(x_test)\n",
    "    \n",
    "    train_hash = calculate_hash(encode_train, from_probas=binary )\n",
    "    test_hash = calculate_hash(encode_test, from_probas = binary)\n",
    "    return train_hash, test_hash\n",
    "\n",
    "#to save results\n",
    "results_dat = {\"mnist\":{},\"mnist-raw\":{},\"cifar-10\":{},\"celeba\":{}, \"nus-wide\":{}} \n",
    "\n",
    "BITS_S = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_total = np.concatenate((X_train,X_val),axis=0)\n",
    "X_total_input = X_total\n",
    "labels_total = np.concatenate((labels_train,labels_val),axis=0)\n",
    "del X_train, X_train_input, X_val, X_val_input, labels_train,labels_val\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-encoder network:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               256500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 500)               2000      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 500)               2000      \n",
      "=================================================================\n",
      "Total params: 511,000\n",
      "Trainable params: 509,000\n",
      "Non-trainable params: 2,000\n",
      "_________________________________________________________________\n",
      "generator network:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               16896     \n",
      "=================================================================\n",
      "Total params: 16,896\n",
      "Trainable params: 16,896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "101117"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_vae,encoder_Bvae,generator_Bvae = binary_VAE(X_total.shape[1],Nb=BITS_S,units=500,layers_e=2,layers_d=0,beta=0,lamb=lambda_B)\n",
    "binary_vae.fit(X_total_input, X_total, epochs=epochs, batch_size=batch_size,verbose=0)\n",
    "#save model\n",
    "encoder_Bvae.save(\"saved_models/\"+name_dat+\"_BAE_\"+str(BITS_S)+\"b_E_VGG_L?avg.h5\")\n",
    "generator_Bvae.save_weights(\"saved_models/\"+name_dat+\"_BAE_\"+str(BITS_S)+\"b_D_VGG_L?avg_w.h5\")\n",
    "\n",
    "keras.backend.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 500)               511000    \n",
      "_________________________________________________________________\n",
      "logits-b (Dense)             (None, 32)                16032     \n",
      "=================================================================\n",
      "Total params: 527,032\n",
      "Trainable params: 525,032\n",
      "Non-trainable params: 2,000\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fmena/.local/lib/python3.5/site-packages/keras/models.py:251: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "##load model\n",
    "encoder_Bvae = keras.models.load_model(\"saved_models/\"+name_dat+\"_BAE_\"+str(BITS_S)+\"b_E_VGG_L?avg.h5\")\n",
    "#generator_Bvae = keras.models.load_model(\"saved_models/\"+name_dat+\"_BAE_\"+str(BITS_S)+\"b_D_defaultCNN.h5\")\n",
    "encoder_Bvae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_hash_BVAE, test_hash_BVAE = hash_data(encoder_Bvae,X_total_input,X_test_input)\n",
    "\n",
    "del X_total_input, X_test_input, X_test, X_total\n",
    "gc.collect()\n",
    "\n",
    "keras.backend.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Realizado.\n"
     ]
    }
   ],
   "source": [
    "dataset = name_dat.lower()\n",
    "\n",
    "p_b,r_b = evaluate_hashing_DE(total_hash_BVAE, test_hash_BVAE,labels_total,labels_test,tipo=\"topK\")\n",
    "results_dat[dataset][\"p\"] = [p_b]\n",
    "results_dat[dataset][\"r\"] = [r_b]\n",
    "p5k_b = evaluate_hashing_DE(total_hash_BVAE, test_hash_BVAE,labels_total,labels_test,eval_tipo=\"Patk\",K=5000)\n",
    "results_dat[dataset][\"p5k\"] = [p5k_b]\n",
    "\n",
    "print(\"Realizado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************Top 100 most similar retrieve*************\n",
      "\n",
      "Resultados de Precision en pruebas\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-c41bc6c4d24f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nResultados de Precision en pruebas\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Table()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Modelo\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Binario\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"MNIST-R\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_dat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mnist-raw\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"p\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"*************Top 100 most similar retrieve*************\")\n",
    "\n",
    "print(\"\\nResultados de Precision en pruebas\")\n",
    "t = pd.DataFrame() #Table()\n",
    "t[\"Modelo\"] = [\"Binario\"]\n",
    "t[\"MNIST-R\"] = results_dat[\"mnist-raw\"][\"p\"]\n",
    "t[\"MNIST\"] = results_dat[\"mnist\"][\"p\"]\n",
    "t[\"CIFAR-10\"] = results_dat[\"cifar-10\"][\"p\"]\n",
    "#t[\"CelebA\"] = results_dat[\"celeba\"][\"p\"]\n",
    "t[\"Nus-Wide\"] = results_dat[\"nus-wide\"][\"p\"]\n",
    "print(t)\n",
    "\n",
    "print(\"\\n\\nResultados de Recall en pruebas\")\n",
    "t = pd.DataFrame() #Table()\n",
    "t[\"Modelo\"] = [\"Binario\"]\n",
    "t[\"MNIST-R\"] = results_dat[\"mnist-raw\"][\"r\"]\n",
    "t[\"MNIST\"] = results_dat[\"mnist\"][\"r\"]\n",
    "t[\"CIFAR-10\"] = results_dat[\"cifar-10\"][\"r\"]\n",
    "#t[\"CelebA\"] = results_dat[\"celeba\"][\"r\"]\n",
    "t[\"Nus-Wide\"] = results_dat[\"nus-wide\"][\"r\"]\n",
    "print(t)\n",
    "\n",
    "print(\"\\n\\nResultados de Precision en pruebas (top-5k)\")\n",
    "t = pd.DataFrame() #Table()\n",
    "t[\"Modelo\"] = [\"Binario\"]\n",
    "t[\"MNIST-R\"] = results_dat[\"mnist-raw\"][\"p5k\"]\n",
    "t[\"MNIST\"] = results_dat[\"mnist\"][\"p5k\"]\n",
    "t[\"CIFAR-10\"] = results_dat[\"cifar-10\"][\"p5k\"]\n",
    "#t[\"CelebA\"] = results_dat[\"celeba\"][\"p5k\"]\n",
    "t[\"Nus-Wide\"] = results_dat[\"nus-wide\"][\"p5k\"]\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'name_dat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a3a7566d5f54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MAP on %s dataset\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mname_dat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmap_b\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mevaluate_hashing_DE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_hash_BVAE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_hash_BVAE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels_total\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meval_tipo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"MAP\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9999999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Binary VAE = \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmap_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#raw estilo binary..\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'name_dat' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"MAP on %s dataset\"%name_dat)\n",
    "map_b= evaluate_hashing_DE(total_hash_BVAE, test_hash_BVAE,labels_total,labels_test,eval_tipo=\"MAP\",K=9999999)\n",
    "print(\"Binary VAE = \",map_b)\n",
    "#raw estilo binary.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'name_dat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-0acf94d6020b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MAP on %s dataset\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mname_dat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmap_b\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mevaluate_hashing_DE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_hash_BVAE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_hash_BVAE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels_total\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meval_tipo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"MAP\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9999999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Binary VAE = \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmap_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'name_dat' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"MAP on %s dataset\"%name_dat)\n",
    "map_b= evaluate_hashing_DE(total_hash_BVAE, test_hash_BVAE,labels_total,labels_test,eval_tipo=\"MAP\",K=9999999)\n",
    "print(\"Binary VAE = \",map_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'name_dat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-0acf94d6020b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MAP on %s dataset\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mname_dat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmap_b\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mevaluate_hashing_DE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_hash_BVAE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_hash_BVAE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels_total\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meval_tipo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"MAP\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9999999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Binary VAE = \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmap_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'name_dat' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"MAP on %s dataset\"%name_dat)\n",
    "map_b= evaluate_hashing_DE(total_hash_BVAE, test_hash_BVAE,labels_total,labels_test,eval_tipo=\"MAP\",K=9999999)\n",
    "print(\"Binary VAE = \",map_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'name_dat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-0acf94d6020b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MAP on %s dataset\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mname_dat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmap_b\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mevaluate_hashing_DE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_hash_BVAE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_hash_BVAE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels_total\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meval_tipo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"MAP\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9999999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Binary VAE = \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmap_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'name_dat' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"MAP on %s dataset\"%name_dat)\n",
    "map_b= evaluate_hashing_DE(total_hash_BVAE, test_hash_BVAE,labels_total,labels_test,eval_tipo=\"MAP\",K=9999999)\n",
    "print(\"Binary VAE = \",map_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'name_dat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-8f3addd2fab0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MAP@5000 on %s dataset\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mname_dat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmap_b\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mevaluate_hashing_DE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_hash_BVAE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_hash_BVAE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels_total\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meval_tipo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"MAP\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Binary VAE = \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmap_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'name_dat' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"MAP@5000 on %s dataset\"%name_dat)\n",
    "map_b= evaluate_hashing_DE(total_hash_BVAE, test_hash_BVAE,labels_total,labels_test,eval_tipo=\"MAP\",K=5000)\n",
    "print(\"Binary VAE = \",map_b)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tesis]",
   "language": "python",
   "name": "conda-env-tesis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
